{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New model : https://medium.com/analytics-vidhya/text-classification-using-word-embeddings-and-deep-learning-in-python-classifying-tweets-from-6fe644fcfc81\n",
    "from scipy.sparse import *\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "import keras\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "from keras.models import model_from_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextToTensor():\n",
    "\n",
    "    def __init__(self, tokenizer, max_len):\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def string_to_tensor(self, string_list: list) -> list:\n",
    "        \"\"\"\n",
    "        A method to convert a string list to a tensor for a deep learning model\n",
    "        \"\"\"    \n",
    "        string_list = self.tokenizer.texts_to_sequences(string_list)\n",
    "        string_list = pad_sequences(string_list, maxlen=self.max_len)\n",
    "        \n",
    "        return string_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load = keras.models.load_model('drive/MyDrive/ML_project/modelfull3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len=20\n",
    "\n",
    "with open('drive/MyDrive/ML_project/ML_proj_final/tokenizer.pickle','rb') as f:\n",
    "    tokenizer = pickle.load(f)\n",
    "TextToTensor_instance = TextToTensor(\n",
    "    tokenizer=tokenizer, \n",
    "    max_len=max_len\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test=[]\n",
    "print('get data')\n",
    "f_test=open('drive/MyDrive/ML_project/ML_proj_final/preprocessed/test_data_lem.txt')\n",
    "for line in f_test:\n",
    "    X_test.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = TextToTensor_instance.string_to_tensor(X_test)\n",
    "yhat = [x[0] for x in model_load.predict(X_test).tolist()]\n",
    "predict=[1 if x > 0.5 else -1 for x in yhat]\n",
    " \n",
    "predict=np.array(predict)  \n",
    "numbers = np.arange(1, predict.size+1)\n",
    "final  = np.c_[numbers, predict]\n",
    "np.savetxt(\"modeltest3.csv\", final , delimiter=\",\",header=\"Id,Prediction\",fmt=\"%i\", comments='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
